{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Affinity\\Anaconda3\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1024 11:45:49.825688  8180 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "# from keras.models import load_model\n",
    "from datetime import datetime\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tfds.load(name='cifar10:3.*.*', split='train[:80%]', as_supervised=True)\n",
    "valid_data = tfds.load(name='cifar10:3.*.*', split='train[80%:]', as_supervised=True)\n",
    "test_data = tfds.load(name='cifar10:3.*.*', split='test', as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                81930     \n",
      "=================================================================\n",
      "Total params: 82,954\n",
      "Trainable params: 82,890\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.BatchNormalization(),  # 키워드 검색하기\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "    \n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    return image, label\n",
    "\n",
    "train_data = train_data.map(scale).shuffle(50000).batch(64) # \n",
    "valid_data = valid_data.map(scale).batch(64)\n",
    "test_data = test_data.map(scale).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(   \n",
    "    'checkpoints/{}.hdf5'.format(dt),\n",
    "    monitor='val_acc',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def on_epoch_start(self, epoch, logs=None):\n",
    "        print('Epoch {} begins at {}: {}'.format(epoch, datetime.now().time(), logs))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print('Epoch {} ends at {}: {}'.format(epoch, datetime.now().time(), logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1024 11:45:53.855840  8180 deprecation.py:323] From C:\\Users\\Affinity\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 ends at 11:47:07.916700: {'loss': 1.599849955177307, 'acc': 0.455275, 'val_loss': 1.348267051824339, 'val_acc': 0.5285}\n",
      "Epoch 1 ends at 11:48:24.922602: {'loss': 1.2564665320396424, 'acc': 0.565425, 'val_loss': 1.3711474784620248, 'val_acc': 0.5276}\n",
      "Epoch 2 ends at 11:49:46.616995: {'loss': 1.1581681792259215, 'acc': 0.596975, 'val_loss': 1.2481447295018822, 'val_acc': 0.5733}\n",
      "Epoch 3 ends at 11:51:03.903185: {'loss': 1.1172106649398803, 'acc': 0.61355, 'val_loss': 1.3349693504868039, 'val_acc': 0.5513}\n",
      "Epoch 4 ends at 11:52:21.490570: {'loss': 1.0742877144813539, 'acc': 0.6267, 'val_loss': 1.250410312300275, 'val_acc': 0.583}\n",
      "Epoch 5 ends at 11:53:38.983206: {'loss': 1.0416087482452392, 'acc': 0.6384, 'val_loss': 1.2514031719250285, 'val_acc': 0.5825}\n",
      "Epoch 6 ends at 11:54:55.892406: {'loss': 1.0250136943817139, 'acc': 0.643425, 'val_loss': 1.2060912885483663, 'val_acc': 0.5965}\n",
      "Epoch 7 ends at 11:56:12.776670: {'loss': 1.0009146723747253, 'acc': 0.647425, 'val_loss': 1.16211395392752, 'val_acc': 0.6063}\n",
      "Epoch 8 ends at 11:57:29.217122: {'loss': 0.9829696219444275, 'acc': 0.658775, 'val_loss': 1.1252524404768731, 'val_acc': 0.6189}\n",
      "Epoch 9 ends at 11:58:45.974728: {'loss': 0.968201535987854, 'acc': 0.660375, 'val_loss': 1.1976367026377635, 'val_acc': 0.6031}\n",
      "Epoch 10 ends at 12:00:06.590009: {'loss': 0.9621358745574952, 'acc': 0.66525, 'val_loss': 1.2122585807636286, 'val_acc': 0.5992}\n",
      "Epoch 11 ends at 12:01:26.591952: {'loss': 0.9408114706039429, 'acc': 0.672475, 'val_loss': 1.1433953244215365, 'val_acc': 0.6176}\n",
      "Epoch 12 ends at 12:02:44.091573: {'loss': 0.9274569857597351, 'acc': 0.67545, 'val_loss': 1.1963411478479957, 'val_acc': 0.6013}\n",
      "Epoch 13 ends at 12:04:01.738795: {'loss': 0.9239614054679871, 'acc': 0.67665, 'val_loss': 1.1703742769113772, 'val_acc': 0.6134}\n",
      "Epoch 14 ends at 12:05:19.717132: {'loss': 0.9130556427955627, 'acc': 0.679675, 'val_loss': 1.1681550285618776, 'val_acc': 0.6185}\n",
      "Epoch 15 ends at 12:06:39.844720: {'loss': 0.9009341920852662, 'acc': 0.684, 'val_loss': 1.1696244034038228, 'val_acc': 0.6188}\n",
      "Epoch 16 ends at 12:07:57.547794: {'loss': 0.8898841109275818, 'acc': 0.68665, 'val_loss': 1.2223084003302702, 'val_acc': 0.5993}\n",
      "Epoch 17 ends at 12:09:15.428394: {'loss': 0.8901964556694031, 'acc': 0.6881, 'val_loss': 1.2299562943209508, 'val_acc': 0.5975}\n",
      "Epoch 18 ends at 12:10:41.382388: {'loss': 0.8823691026687622, 'acc': 0.691375, 'val_loss': 1.1726364607264281, 'val_acc': 0.617}\n",
      "Epoch 19 ends at 12:12:01.367356: {'loss': 0.8762848867416382, 'acc': 0.692575, 'val_loss': 1.1528095530856186, 'val_acc': 0.6247}\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,\n",
    "                    epochs=20,\n",
    "                    validation_data=valid_data,\n",
    "                    verbose=0,\n",
    "                    callbacks=[cp_callback, MyCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    157/Unknown - 0s 48ms/step - loss: 1.1983 - acc: 0.625 - 0s 32ms/step - loss: 1.1480 - acc: 0.640 - 0s 26ms/step - loss: 1.2004 - acc: 0.640 - 0s 25ms/step - loss: 1.1521 - acc: 0.664 - 0s 23ms/step - loss: 1.0946 - acc: 0.675 - 0s 23ms/step - loss: 1.0814 - acc: 0.664 - 0s 23ms/step - loss: 1.0958 - acc: 0.660 - 0s 22ms/step - loss: 1.1034 - acc: 0.652 - 0s 22ms/step - loss: 1.1051 - acc: 0.652 - 0s 21ms/step - loss: 1.1004 - acc: 0.660 - 0s 21ms/step - loss: 1.0848 - acc: 0.664 - 0s 21ms/step - loss: 1.1123 - acc: 0.660 - 0s 21ms/step - loss: 1.1189 - acc: 0.658 - 0s 21ms/step - loss: 1.1294 - acc: 0.651 - 0s 21ms/step - loss: 1.1344 - acc: 0.647 - 0s 21ms/step - loss: 1.1414 - acc: 0.641 - 0s 21ms/step - loss: 1.1392 - acc: 0.641 - 0s 20ms/step - loss: 1.1342 - acc: 0.638 - 0s 20ms/step - loss: 1.1414 - acc: 0.634 - 0s 20ms/step - loss: 1.1625 - acc: 0.630 - 0s 20ms/step - loss: 1.1361 - acc: 0.638 - 0s 20ms/step - loss: 1.1277 - acc: 0.639 - 0s 20ms/step - loss: 1.1281 - acc: 0.637 - 0s 20ms/step - loss: 1.1259 - acc: 0.636 - 0s 20ms/step - loss: 1.1164 - acc: 0.640 - 1s 20ms/step - loss: 1.1128 - acc: 0.641 - 1s 20ms/step - loss: 1.1100 - acc: 0.642 - 1s 20ms/step - loss: 1.1003 - acc: 0.644 - 1s 20ms/step - loss: 1.1041 - acc: 0.641 - 1s 20ms/step - loss: 1.1061 - acc: 0.641 - 1s 20ms/step - loss: 1.1057 - acc: 0.643 - 1s 20ms/step - loss: 1.0926 - acc: 0.647 - 1s 20ms/step - loss: 1.0995 - acc: 0.643 - 1s 20ms/step - loss: 1.1043 - acc: 0.641 - 1s 20ms/step - loss: 1.1008 - acc: 0.641 - 1s 20ms/step - loss: 1.0984 - acc: 0.643 - 1s 20ms/step - loss: 1.1017 - acc: 0.641 - 1s 20ms/step - loss: 1.1011 - acc: 0.639 - 1s 20ms/step - loss: 1.1015 - acc: 0.640 - 1s 20ms/step - loss: 1.0991 - acc: 0.640 - 1s 20ms/step - loss: 1.1008 - acc: 0.640 - 1s 20ms/step - loss: 1.0965 - acc: 0.640 - 1s 20ms/step - loss: 1.0969 - acc: 0.639 - 1s 20ms/step - loss: 1.1038 - acc: 0.638 - 1s 20ms/step - loss: 1.0983 - acc: 0.640 - 1s 20ms/step - loss: 1.1001 - acc: 0.637 - 1s 20ms/step - loss: 1.0986 - acc: 0.637 - 1s 20ms/step - loss: 1.0969 - acc: 0.638 - 1s 20ms/step - loss: 1.0976 - acc: 0.638 - 1s 20ms/step - loss: 1.1013 - acc: 0.637 - 1s 20ms/step - loss: 1.1004 - acc: 0.636 - 1s 20ms/step - loss: 1.0998 - acc: 0.637 - 1s 20ms/step - loss: 1.1140 - acc: 0.635 - 1s 20ms/step - loss: 1.1160 - acc: 0.634 - 1s 20ms/step - loss: 1.1114 - acc: 0.636 - 1s 20ms/step - loss: 1.1115 - acc: 0.635 - 1s 20ms/step - loss: 1.1079 - acc: 0.635 - 1s 20ms/step - loss: 1.1109 - acc: 0.633 - 1s 20ms/step - loss: 1.1094 - acc: 0.634 - 1s 20ms/step - loss: 1.1147 - acc: 0.632 - 1s 20ms/step - loss: 1.1130 - acc: 0.634 - 1s 20ms/step - loss: 1.1182 - acc: 0.632 - 1s 20ms/step - loss: 1.1184 - acc: 0.632 - 1s 20ms/step - loss: 1.1235 - acc: 0.631 - 1s 20ms/step - loss: 1.1233 - acc: 0.632 - 1s 20ms/step - loss: 1.1229 - acc: 0.632 - 1s 20ms/step - loss: 1.1227 - acc: 0.631 - 1s 20ms/step - loss: 1.1264 - acc: 0.629 - 1s 20ms/step - loss: 1.1239 - acc: 0.629 - 1s 20ms/step - loss: 1.1216 - acc: 0.630 - 1s 20ms/step - loss: 1.1244 - acc: 0.629 - 1s 20ms/step - loss: 1.1278 - acc: 0.628 - 1s 20ms/step - loss: 1.1303 - acc: 0.628 - 1s 20ms/step - loss: 1.1263 - acc: 0.629 - 1s 20ms/step - loss: 1.1243 - acc: 0.630 - 2s 20ms/step - loss: 1.1230 - acc: 0.629 - 2s 20ms/step - loss: 1.1223 - acc: 0.630 - 2s 20ms/step - loss: 1.1211 - acc: 0.630 - 2s 20ms/step - loss: 1.1188 - acc: 0.630 - 2s 20ms/step - loss: 1.1167 - acc: 0.631 - 2s 20ms/step - loss: 1.1143 - acc: 0.632 - 2s 20ms/step - loss: 1.1124 - acc: 0.632 - 2s 20ms/step - loss: 1.1114 - acc: 0.632 - 2s 20ms/step - loss: 1.1138 - acc: 0.632 - 2s 20ms/step - loss: 1.1135 - acc: 0.632 - 2s 20ms/step - loss: 1.1137 - acc: 0.631 - 2s 20ms/step - loss: 1.1138 - acc: 0.631 - 2s 20ms/step - loss: 1.1143 - acc: 0.631 - 2s 20ms/step - loss: 1.1151 - acc: 0.630 - 2s 20ms/step - loss: 1.1205 - acc: 0.629 - 2s 20ms/step - loss: 1.1254 - acc: 0.628 - 2s 20ms/step - loss: 1.1240 - acc: 0.628 - 2s 20ms/step - loss: 1.1222 - acc: 0.630 - 2s 20ms/step - loss: 1.1260 - acc: 0.629 - 2s 20ms/step - loss: 1.1308 - acc: 0.628 - 2s 20ms/step - loss: 1.1301 - acc: 0.628 - 2s 20ms/step - loss: 1.1330 - acc: 0.626 - 2s 20ms/step - loss: 1.1338 - acc: 0.626 - 2s 20ms/step - loss: 1.1342 - acc: 0.625 - 2s 20ms/step - loss: 1.1332 - acc: 0.626 - 2s 20ms/step - loss: 1.1343 - acc: 0.625 - 2s 20ms/step - loss: 1.1316 - acc: 0.625 - 2s 20ms/step - loss: 1.1323 - acc: 0.625 - 2s 20ms/step - loss: 1.1344 - acc: 0.624 - 2s 20ms/step - loss: 1.1361 - acc: 0.624 - 2s 20ms/step - loss: 1.1406 - acc: 0.624 - 2s 20ms/step - loss: 1.1390 - acc: 0.624 - 2s 20ms/step - loss: 1.1373 - acc: 0.625 - 2s 20ms/step - loss: 1.1380 - acc: 0.624 - 2s 20ms/step - loss: 1.1414 - acc: 0.624 - 2s 20ms/step - loss: 1.1410 - acc: 0.624 - 2s 20ms/step - loss: 1.1417 - acc: 0.623 - 2s 20ms/step - loss: 1.1430 - acc: 0.623 - 2s 20ms/step - loss: 1.1425 - acc: 0.623 - 2s 20ms/step - loss: 1.1425 - acc: 0.623 - 2s 20ms/step - loss: 1.1438 - acc: 0.623 - 2s 20ms/step - loss: 1.1445 - acc: 0.624 - 2s 20ms/step - loss: 1.1457 - acc: 0.623 - 2s 20ms/step - loss: 1.1450 - acc: 0.624 - 2s 20ms/step - loss: 1.1455 - acc: 0.624 - 2s 20ms/step - loss: 1.1461 - acc: 0.624 - 2s 20ms/step - loss: 1.1446 - acc: 0.624 - 2s 20ms/step - loss: 1.1451 - acc: 0.624 - 2s 20ms/step - loss: 1.1463 - acc: 0.623 - 2s 20ms/step - loss: 1.1466 - acc: 0.624 - 3s 20ms/step - loss: 1.1461 - acc: 0.624 - 3s 20ms/step - loss: 1.1462 - acc: 0.623 - 3s 20ms/step - loss: 1.1456 - acc: 0.624 - 3s 20ms/step - loss: 1.1451 - acc: 0.624 - 3s 20ms/step - loss: 1.1437 - acc: 0.624 - 3s 20ms/step - loss: 1.1423 - acc: 0.625 - 3s 20ms/step - loss: 1.1415 - acc: 0.625 - 3s 20ms/step - loss: 1.1430 - acc: 0.624 - 3s 20ms/step - loss: 1.1423 - acc: 0.624 - 3s 20ms/step - loss: 1.1397 - acc: 0.625 - 3s 20ms/step - loss: 1.1415 - acc: 0.625 - 3s 20ms/step - loss: 1.1429 - acc: 0.625 - 3s 20ms/step - loss: 1.1427 - acc: 0.624 - 3s 20ms/step - loss: 1.1437 - acc: 0.625 - 3s 20ms/step - loss: 1.1439 - acc: 0.625 - 3s 20ms/step - loss: 1.1440 - acc: 0.625 - 3s 20ms/step - loss: 1.1443 - acc: 0.625 - 3s 20ms/step - loss: 1.1442 - acc: 0.625 - 3s 20ms/step - loss: 1.1431 - acc: 0.625 - 3s 20ms/step - loss: 1.1420 - acc: 0.626 - 3s 20ms/step - loss: 1.1417 - acc: 0.626 - 3s 20ms/step - loss: 1.1417 - acc: 0.625 - 3s 20ms/step - loss: 1.1419 - acc: 0.626 - 3s 20ms/step - loss: 1.1418 - acc: 0.626 - 3s 20ms/step - loss: 1.1418 - acc: 0.625 - 3s 20ms/step - loss: 1.1407 - acc: 0.625 - 3s 20ms/step - loss: 1.1400 - acc: 0.626 - 3s 20ms/step - loss: 1.1403 - acc: 0.625 - 3s 20ms/step - loss: 1.1400 - acc: 0.625 - 3s 20ms/step - loss: 1.1419 - acc: 0.625 - 3s 20ms/step - loss: 1.1427 - acc: 0.625 - 3s 20ms/step - loss: 1.1459 - acc: 0.624 - 3s 20ms/step - loss: 1.1459 - acc: 0.6247"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1458908919316189, 0.6247]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.models.load_model('checkpoints/{}.hdf5'.format(dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                81930     \n",
      "=================================================================\n",
      "Total params: 82,954\n",
      "Trainable params: 82,890\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    157/Unknown - 0s 95ms/step - loss: 1.1983 - acc: 0.625 - 0s 53ms/step - loss: 1.1480 - acc: 0.640 - 0s 40ms/step - loss: 1.2004 - acc: 0.640 - 0s 33ms/step - loss: 1.1521 - acc: 0.664 - 0s 29ms/step - loss: 1.0946 - acc: 0.675 - 0s 26ms/step - loss: 1.0814 - acc: 0.664 - 0s 25ms/step - loss: 1.0958 - acc: 0.660 - 0s 24ms/step - loss: 1.1034 - acc: 0.652 - 0s 23ms/step - loss: 1.1051 - acc: 0.652 - 0s 22ms/step - loss: 1.1004 - acc: 0.660 - 0s 21ms/step - loss: 1.0848 - acc: 0.664 - 0s 21ms/step - loss: 1.1123 - acc: 0.660 - 0s 20ms/step - loss: 1.1189 - acc: 0.658 - 0s 20ms/step - loss: 1.1294 - acc: 0.651 - 0s 20ms/step - loss: 1.1344 - acc: 0.647 - 0s 19ms/step - loss: 1.1414 - acc: 0.641 - 0s 19ms/step - loss: 1.1392 - acc: 0.641 - 0s 19ms/step - loss: 1.1342 - acc: 0.638 - 0s 19ms/step - loss: 1.1414 - acc: 0.634 - 0s 19ms/step - loss: 1.1625 - acc: 0.630 - 0s 19ms/step - loss: 1.1361 - acc: 0.638 - 0s 18ms/step - loss: 1.1277 - acc: 0.639 - 0s 18ms/step - loss: 1.1281 - acc: 0.637 - 0s 18ms/step - loss: 1.1259 - acc: 0.636 - 0s 18ms/step - loss: 1.1164 - acc: 0.640 - 0s 18ms/step - loss: 1.1128 - acc: 0.641 - 0s 18ms/step - loss: 1.1100 - acc: 0.642 - 1s 18ms/step - loss: 1.1003 - acc: 0.644 - 1s 18ms/step - loss: 1.1041 - acc: 0.641 - 1s 18ms/step - loss: 1.1061 - acc: 0.641 - 1s 18ms/step - loss: 1.1057 - acc: 0.643 - 1s 18ms/step - loss: 1.0926 - acc: 0.647 - 1s 18ms/step - loss: 1.0995 - acc: 0.643 - 1s 18ms/step - loss: 1.1043 - acc: 0.641 - 1s 18ms/step - loss: 1.1008 - acc: 0.641 - 1s 18ms/step - loss: 1.0984 - acc: 0.643 - 1s 17ms/step - loss: 1.1017 - acc: 0.641 - 1s 17ms/step - loss: 1.1011 - acc: 0.639 - 1s 17ms/step - loss: 1.1015 - acc: 0.640 - 1s 17ms/step - loss: 1.0991 - acc: 0.640 - 1s 17ms/step - loss: 1.1008 - acc: 0.640 - 1s 17ms/step - loss: 1.0965 - acc: 0.640 - 1s 17ms/step - loss: 1.0969 - acc: 0.639 - 1s 17ms/step - loss: 1.1038 - acc: 0.638 - 1s 17ms/step - loss: 1.0983 - acc: 0.640 - 1s 17ms/step - loss: 1.1001 - acc: 0.637 - 1s 17ms/step - loss: 1.0986 - acc: 0.637 - 1s 17ms/step - loss: 1.0969 - acc: 0.638 - 1s 17ms/step - loss: 1.0976 - acc: 0.638 - 1s 17ms/step - loss: 1.1013 - acc: 0.637 - 1s 17ms/step - loss: 1.1004 - acc: 0.636 - 1s 17ms/step - loss: 1.0998 - acc: 0.637 - 1s 17ms/step - loss: 1.1140 - acc: 0.635 - 1s 17ms/step - loss: 1.1160 - acc: 0.634 - 1s 17ms/step - loss: 1.1114 - acc: 0.636 - 1s 17ms/step - loss: 1.1115 - acc: 0.635 - 1s 17ms/step - loss: 1.1079 - acc: 0.635 - 1s 17ms/step - loss: 1.1109 - acc: 0.633 - 1s 17ms/step - loss: 1.1094 - acc: 0.634 - 1s 17ms/step - loss: 1.1147 - acc: 0.632 - 1s 17ms/step - loss: 1.1130 - acc: 0.634 - 1s 17ms/step - loss: 1.1182 - acc: 0.632 - 1s 17ms/step - loss: 1.1184 - acc: 0.632 - 1s 17ms/step - loss: 1.1235 - acc: 0.631 - 1s 17ms/step - loss: 1.1233 - acc: 0.632 - 1s 17ms/step - loss: 1.1229 - acc: 0.632 - 1s 17ms/step - loss: 1.1227 - acc: 0.631 - 1s 17ms/step - loss: 1.1264 - acc: 0.629 - 1s 17ms/step - loss: 1.1239 - acc: 0.629 - 1s 17ms/step - loss: 1.1216 - acc: 0.630 - 1s 17ms/step - loss: 1.1244 - acc: 0.629 - 1s 17ms/step - loss: 1.1278 - acc: 0.628 - 1s 17ms/step - loss: 1.1303 - acc: 0.628 - 1s 17ms/step - loss: 1.1263 - acc: 0.629 - 1s 17ms/step - loss: 1.1243 - acc: 0.630 - 1s 17ms/step - loss: 1.1230 - acc: 0.629 - 1s 17ms/step - loss: 1.1223 - acc: 0.630 - 1s 17ms/step - loss: 1.1211 - acc: 0.630 - 1s 17ms/step - loss: 1.1188 - acc: 0.630 - 1s 17ms/step - loss: 1.1167 - acc: 0.631 - 1s 17ms/step - loss: 1.1143 - acc: 0.632 - 1s 17ms/step - loss: 1.1124 - acc: 0.632 - 1s 17ms/step - loss: 1.1114 - acc: 0.632 - 1s 17ms/step - loss: 1.1138 - acc: 0.632 - 1s 17ms/step - loss: 1.1135 - acc: 0.632 - 1s 17ms/step - loss: 1.1137 - acc: 0.631 - 1s 17ms/step - loss: 1.1138 - acc: 0.631 - 1s 17ms/step - loss: 1.1143 - acc: 0.631 - 1s 17ms/step - loss: 1.1151 - acc: 0.630 - 1s 17ms/step - loss: 1.1205 - acc: 0.629 - 2s 17ms/step - loss: 1.1254 - acc: 0.628 - 2s 17ms/step - loss: 1.1240 - acc: 0.628 - 2s 17ms/step - loss: 1.1222 - acc: 0.630 - 2s 17ms/step - loss: 1.1260 - acc: 0.629 - 2s 17ms/step - loss: 1.1308 - acc: 0.628 - 2s 17ms/step - loss: 1.1301 - acc: 0.628 - 2s 17ms/step - loss: 1.1330 - acc: 0.626 - 2s 16ms/step - loss: 1.1338 - acc: 0.626 - 2s 16ms/step - loss: 1.1342 - acc: 0.625 - 2s 16ms/step - loss: 1.1332 - acc: 0.626 - 2s 16ms/step - loss: 1.1343 - acc: 0.625 - 2s 16ms/step - loss: 1.1316 - acc: 0.625 - 2s 16ms/step - loss: 1.1323 - acc: 0.625 - 2s 16ms/step - loss: 1.1344 - acc: 0.624 - 2s 16ms/step - loss: 1.1361 - acc: 0.624 - 2s 16ms/step - loss: 1.1406 - acc: 0.624 - 2s 16ms/step - loss: 1.1390 - acc: 0.624 - 2s 16ms/step - loss: 1.1373 - acc: 0.625 - 2s 16ms/step - loss: 1.1380 - acc: 0.624 - 2s 16ms/step - loss: 1.1414 - acc: 0.624 - 2s 16ms/step - loss: 1.1410 - acc: 0.624 - 2s 16ms/step - loss: 1.1417 - acc: 0.623 - 2s 16ms/step - loss: 1.1430 - acc: 0.623 - 2s 16ms/step - loss: 1.1425 - acc: 0.623 - 2s 16ms/step - loss: 1.1425 - acc: 0.623 - 2s 16ms/step - loss: 1.1438 - acc: 0.623 - 2s 16ms/step - loss: 1.1445 - acc: 0.624 - 2s 16ms/step - loss: 1.1457 - acc: 0.623 - 2s 16ms/step - loss: 1.1450 - acc: 0.624 - 2s 16ms/step - loss: 1.1455 - acc: 0.624 - 2s 16ms/step - loss: 1.1461 - acc: 0.624 - 2s 16ms/step - loss: 1.1446 - acc: 0.624 - 2s 16ms/step - loss: 1.1451 - acc: 0.624 - 2s 16ms/step - loss: 1.1463 - acc: 0.623 - 2s 16ms/step - loss: 1.1466 - acc: 0.624 - 2s 16ms/step - loss: 1.1461 - acc: 0.624 - 2s 16ms/step - loss: 1.1462 - acc: 0.623 - 2s 16ms/step - loss: 1.1456 - acc: 0.624 - 2s 16ms/step - loss: 1.1451 - acc: 0.624 - 2s 16ms/step - loss: 1.1437 - acc: 0.624 - 2s 16ms/step - loss: 1.1423 - acc: 0.625 - 2s 16ms/step - loss: 1.1415 - acc: 0.625 - 2s 16ms/step - loss: 1.1430 - acc: 0.624 - 2s 16ms/step - loss: 1.1423 - acc: 0.624 - 2s 16ms/step - loss: 1.1397 - acc: 0.625 - 2s 16ms/step - loss: 1.1415 - acc: 0.625 - 2s 16ms/step - loss: 1.1429 - acc: 0.625 - 2s 16ms/step - loss: 1.1427 - acc: 0.624 - 2s 16ms/step - loss: 1.1437 - acc: 0.625 - 2s 16ms/step - loss: 1.1439 - acc: 0.625 - 2s 16ms/step - loss: 1.1440 - acc: 0.625 - 2s 16ms/step - loss: 1.1443 - acc: 0.625 - 2s 16ms/step - loss: 1.1442 - acc: 0.625 - 2s 16ms/step - loss: 1.1431 - acc: 0.625 - 2s 16ms/step - loss: 1.1420 - acc: 0.626 - 2s 16ms/step - loss: 1.1417 - acc: 0.626 - 2s 16ms/step - loss: 1.1417 - acc: 0.625 - 2s 16ms/step - loss: 1.1419 - acc: 0.626 - 2s 16ms/step - loss: 1.1418 - acc: 0.626 - 2s 16ms/step - loss: 1.1418 - acc: 0.625 - 2s 16ms/step - loss: 1.1407 - acc: 0.625 - 2s 16ms/step - loss: 1.1400 - acc: 0.626 - 2s 16ms/step - loss: 1.1403 - acc: 0.625 - 2s 16ms/step - loss: 1.1400 - acc: 0.625 - 2s 16ms/step - loss: 1.1419 - acc: 0.625 - 2s 16ms/step - loss: 1.1427 - acc: 0.625 - 3s 16ms/step - loss: 1.1459 - acc: 0.624 - 3s 16ms/step - loss: 1.1459 - acc: 0.6247"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1458908919316189, 0.6247]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    157/Unknown - 0s 176ms/step - loss: 1.6076 - acc: 0.54 - 0s 95ms/step - loss: 1.2773 - acc: 0.6016 - 0s 70ms/step - loss: 1.3254 - acc: 0.604 - 0s 56ms/step - loss: 1.2340 - acc: 0.613 - 0s 48ms/step - loss: 1.2387 - acc: 0.615 - 0s 43ms/step - loss: 1.2605 - acc: 0.599 - 0s 39ms/step - loss: 1.2772 - acc: 0.607 - 0s 36ms/step - loss: 1.2300 - acc: 0.617 - 0s 34ms/step - loss: 1.2214 - acc: 0.619 - 0s 32ms/step - loss: 1.2111 - acc: 0.621 - 0s 30ms/step - loss: 1.2089 - acc: 0.613 - 0s 29ms/step - loss: 1.2083 - acc: 0.610 - 0s 28ms/step - loss: 1.1815 - acc: 0.616 - 0s 27ms/step - loss: 1.1839 - acc: 0.616 - 0s 26ms/step - loss: 1.1811 - acc: 0.617 - 0s 25ms/step - loss: 1.1855 - acc: 0.618 - 0s 25ms/step - loss: 1.1575 - acc: 0.627 - 0s 24ms/step - loss: 1.1709 - acc: 0.625 - 0s 24ms/step - loss: 1.1589 - acc: 0.629 - 0s 23ms/step - loss: 1.1529 - acc: 0.631 - 0s 23ms/step - loss: 1.1557 - acc: 0.628 - 0s 23ms/step - loss: 1.1547 - acc: 0.631 - 1s 22ms/step - loss: 1.1481 - acc: 0.632 - 1s 22ms/step - loss: 1.1465 - acc: 0.633 - 1s 22ms/step - loss: 1.1468 - acc: 0.630 - 1s 22ms/step - loss: 1.1440 - acc: 0.629 - 1s 22ms/step - loss: 1.1501 - acc: 0.628 - 1s 21ms/step - loss: 1.1474 - acc: 0.625 - 1s 21ms/step - loss: 1.1411 - acc: 0.625 - 1s 21ms/step - loss: 1.1426 - acc: 0.627 - 1s 21ms/step - loss: 1.1470 - acc: 0.626 - 1s 21ms/step - loss: 1.1380 - acc: 0.627 - 1s 21ms/step - loss: 1.1457 - acc: 0.628 - 1s 20ms/step - loss: 1.1452 - acc: 0.628 - 1s 20ms/step - loss: 1.1426 - acc: 0.630 - 1s 20ms/step - loss: 1.1451 - acc: 0.629 - 1s 20ms/step - loss: 1.1586 - acc: 0.627 - 1s 20ms/step - loss: 1.1574 - acc: 0.628 - 1s 20ms/step - loss: 1.1496 - acc: 0.629 - 1s 20ms/step - loss: 1.1546 - acc: 0.627 - 1s 20ms/step - loss: 1.1511 - acc: 0.627 - 1s 19ms/step - loss: 1.1564 - acc: 0.627 - 1s 19ms/step - loss: 1.1561 - acc: 0.627 - 1s 19ms/step - loss: 1.1556 - acc: 0.628 - 1s 19ms/step - loss: 1.1527 - acc: 0.629 - 1s 19ms/step - loss: 1.1526 - acc: 0.627 - 1s 19ms/step - loss: 1.1522 - acc: 0.627 - 1s 19ms/step - loss: 1.1490 - acc: 0.628 - 1s 19ms/step - loss: 1.1512 - acc: 0.626 - 1s 19ms/step - loss: 1.1511 - acc: 0.626 - 1s 19ms/step - loss: 1.1523 - acc: 0.626 - 1s 19ms/step - loss: 1.1565 - acc: 0.625 - 1s 19ms/step - loss: 1.1545 - acc: 0.625 - 1s 19ms/step - loss: 1.1582 - acc: 0.624 - 1s 19ms/step - loss: 1.1566 - acc: 0.623 - 1s 19ms/step - loss: 1.1603 - acc: 0.622 - 1s 19ms/step - loss: 1.1565 - acc: 0.623 - 1s 19ms/step - loss: 1.1562 - acc: 0.622 - 1s 19ms/step - loss: 1.1557 - acc: 0.623 - 1s 18ms/step - loss: 1.1571 - acc: 0.622 - 1s 18ms/step - loss: 1.1598 - acc: 0.622 - 1s 18ms/step - loss: 1.1623 - acc: 0.621 - 1s 18ms/step - loss: 1.1581 - acc: 0.624 - 1s 18ms/step - loss: 1.1580 - acc: 0.624 - 1s 18ms/step - loss: 1.1543 - acc: 0.625 - 1s 18ms/step - loss: 1.1519 - acc: 0.625 - 1s 18ms/step - loss: 1.1535 - acc: 0.625 - 1s 18ms/step - loss: 1.1536 - acc: 0.625 - 1s 18ms/step - loss: 1.1535 - acc: 0.625 - 1s 18ms/step - loss: 1.1557 - acc: 0.625 - 1s 18ms/step - loss: 1.1571 - acc: 0.624 - 1s 18ms/step - loss: 1.1547 - acc: 0.623 - 1s 18ms/step - loss: 1.1542 - acc: 0.624 - 1s 18ms/step - loss: 1.1601 - acc: 0.622 - 1s 18ms/step - loss: 1.1613 - acc: 0.621 - 1s 18ms/step - loss: 1.1604 - acc: 0.621 - 1s 18ms/step - loss: 1.1607 - acc: 0.621 - 1s 18ms/step - loss: 1.1585 - acc: 0.621 - 1s 18ms/step - loss: 1.1585 - acc: 0.620 - 1s 18ms/step - loss: 1.1616 - acc: 0.620 - 1s 18ms/step - loss: 1.1605 - acc: 0.619 - 1s 18ms/step - loss: 1.1626 - acc: 0.617 - 1s 18ms/step - loss: 1.1642 - acc: 0.617 - 1s 18ms/step - loss: 1.1622 - acc: 0.618 - 1s 18ms/step - loss: 1.1619 - acc: 0.617 - 2s 18ms/step - loss: 1.1581 - acc: 0.619 - 2s 18ms/step - loss: 1.1574 - acc: 0.619 - 2s 18ms/step - loss: 1.1588 - acc: 0.618 - 2s 18ms/step - loss: 1.1567 - acc: 0.619 - 2s 18ms/step - loss: 1.1549 - acc: 0.619 - 2s 18ms/step - loss: 1.1576 - acc: 0.618 - 2s 17ms/step - loss: 1.1582 - acc: 0.618 - 2s 17ms/step - loss: 1.1619 - acc: 0.618 - 2s 17ms/step - loss: 1.1584 - acc: 0.619 - 2s 17ms/step - loss: 1.1585 - acc: 0.619 - 2s 17ms/step - loss: 1.1598 - acc: 0.619 - 2s 17ms/step - loss: 1.1642 - acc: 0.617 - 2s 17ms/step - loss: 1.1626 - acc: 0.618 - 2s 17ms/step - loss: 1.1623 - acc: 0.617 - 2s 17ms/step - loss: 1.1660 - acc: 0.616 - 2s 17ms/step - loss: 1.1652 - acc: 0.617 - 2s 17ms/step - loss: 1.1664 - acc: 0.617 - 2s 17ms/step - loss: 1.1666 - acc: 0.617 - 2s 17ms/step - loss: 1.1664 - acc: 0.617 - 2s 17ms/step - loss: 1.1644 - acc: 0.617 - 2s 17ms/step - loss: 1.1660 - acc: 0.617 - 2s 17ms/step - loss: 1.1675 - acc: 0.617 - 2s 17ms/step - loss: 1.1687 - acc: 0.616 - 2s 17ms/step - loss: 1.1692 - acc: 0.615 - 2s 17ms/step - loss: 1.1691 - acc: 0.615 - 2s 17ms/step - loss: 1.1699 - acc: 0.616 - 2s 17ms/step - loss: 1.1693 - acc: 0.616 - 2s 17ms/step - loss: 1.1715 - acc: 0.616 - 2s 17ms/step - loss: 1.1711 - acc: 0.616 - 2s 17ms/step - loss: 1.1718 - acc: 0.616 - 2s 17ms/step - loss: 1.1725 - acc: 0.617 - 2s 17ms/step - loss: 1.1715 - acc: 0.617 - 2s 17ms/step - loss: 1.1709 - acc: 0.618 - 2s 17ms/step - loss: 1.1724 - acc: 0.618 - 2s 17ms/step - loss: 1.1697 - acc: 0.619 - 2s 17ms/step - loss: 1.1702 - acc: 0.618 - 2s 17ms/step - loss: 1.1696 - acc: 0.619 - 2s 17ms/step - loss: 1.1684 - acc: 0.619 - 2s 17ms/step - loss: 1.1710 - acc: 0.619 - 2s 17ms/step - loss: 1.1686 - acc: 0.620 - 2s 17ms/step - loss: 1.1690 - acc: 0.619 - 2s 17ms/step - loss: 1.1681 - acc: 0.619 - 2s 17ms/step - loss: 1.1674 - acc: 0.619 - 2s 17ms/step - loss: 1.1672 - acc: 0.619 - 2s 17ms/step - loss: 1.1684 - acc: 0.618 - 2s 17ms/step - loss: 1.1669 - acc: 0.619 - 2s 17ms/step - loss: 1.1667 - acc: 0.619 - 2s 17ms/step - loss: 1.1667 - acc: 0.619 - 2s 17ms/step - loss: 1.1667 - acc: 0.619 - 2s 17ms/step - loss: 1.1655 - acc: 0.619 - 2s 17ms/step - loss: 1.1631 - acc: 0.620 - 2s 17ms/step - loss: 1.1646 - acc: 0.620 - 2s 17ms/step - loss: 1.1635 - acc: 0.620 - 2s 17ms/step - loss: 1.1622 - acc: 0.621 - 2s 17ms/step - loss: 1.1627 - acc: 0.620 - 2s 17ms/step - loss: 1.1615 - acc: 0.620 - 2s 17ms/step - loss: 1.1595 - acc: 0.621 - 2s 17ms/step - loss: 1.1612 - acc: 0.621 - 2s 17ms/step - loss: 1.1606 - acc: 0.621 - 2s 17ms/step - loss: 1.1589 - acc: 0.622 - 2s 17ms/step - loss: 1.1580 - acc: 0.622 - 2s 17ms/step - loss: 1.1582 - acc: 0.622 - 2s 17ms/step - loss: 1.1565 - acc: 0.623 - 2s 17ms/step - loss: 1.1568 - acc: 0.623 - 2s 17ms/step - loss: 1.1560 - acc: 0.623 - 3s 17ms/step - loss: 1.1587 - acc: 0.623 - 3s 17ms/step - loss: 1.1582 - acc: 0.623 - 3s 17ms/step - loss: 1.1565 - acc: 0.624 - 3s 17ms/step - loss: 1.1552 - acc: 0.624 - 3s 17ms/step - loss: 1.1538 - acc: 0.624 - 3s 17ms/step - loss: 1.1525 - acc: 0.624 - 3s 16ms/step - loss: 1.1528 - acc: 0.624 - 3s 17ms/step - loss: 1.1528 - acc: 0.6247"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1528095530856186, 0.6247]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20191024-114550'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
