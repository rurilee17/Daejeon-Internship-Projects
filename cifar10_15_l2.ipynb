{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-datasets in c:\\users\\affinity\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (2.22.0)\n",
      "Requirement already satisfied: attrs in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (19.3.0)\n",
      "Requirement already satisfied: six in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (1.12.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (1.1.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.8.0)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.15.0)\n",
      "Requirement already satisfied: dill in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.3.1.1)\n",
      "Requirement already satisfied: promise in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (2.2.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (4.36.1)\n",
      "Requirement already satisfied: future in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.17.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (3.9.2)\n",
      "Requirement already satisfied: wrapt in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (1.11.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (1.16.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2.8)\n",
      "Requirement already satisfied: googleapis-common-protos in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-metadata->tensorflow-datasets) (1.6.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow-datasets) (41.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in c:\\users\\affinity\\anaconda3\\lib\\site-packages (19.3.1)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.models import load_model\n",
    "from datetime import datetime\n",
    "#tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tfds.load(name='cifar10:3.*.*', split='train[:80%]', as_supervised=True)\n",
    "valid_data = tfds.load(name='cifar10:3.*.*', split='train[80%:]', as_supervised=True)\n",
    "test_data = tfds.load(name='cifar10:3.*.*', split='test', as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 128)       3584      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                81930     \n",
      "=================================================================\n",
      "Total params: 4,514,314\n",
      "Trainable params: 4,512,522\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.BatchNormalization(),  # Gradient Vanishing / Gradient Exploding 이 일어나지 않도록 하는 아이디어 중의 하나이다\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='softmax', bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "    \n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    return image, label\n",
    "\n",
    "train_data = train_data.map(scale).shuffle(50000).repeat(2).batch(64) \n",
    "valid_data = valid_data.map(scale).batch(64)\n",
    "test_data = test_data.map(scale).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(   \n",
    "    'checkpoints/{}.hdf5'.format(dt),\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def on_epoch_start(self, epoch, logs=None):\n",
    "        print('Epoch {} begins at {}: {}'.format(epoch, datetime.now().time(), logs))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print('Epoch {} ends at {}: {}'.format(epoch, datetime.now().time(), logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 ends at 14:25:31.738958: {'loss': 2.252607939815521, 'accuracy': 0.441875, 'val_loss': 2.1165035549242783, 'val_accuracy': 0.5149}\n",
      "Epoch 1 ends at 14:27:36.342308: {'loss': 1.338231166601181, 'accuracy': 0.6125125, 'val_loss': 1.227925189741098, 'val_accuracy': 0.5846}\n",
      "Epoch 2 ends at 14:29:42.138436: {'loss': 0.9187158030748367, 'accuracy': 0.7023375, 'val_loss': 0.9297789247931948, 'val_accuracy': 0.6977}\n",
      "Epoch 3 ends at 14:31:48.459174: {'loss': 0.6774426629781723, 'accuracy': 0.7713125, 'val_loss': 0.7447370152184918, 'val_accuracy': 0.7462}\n",
      "Epoch 4 ends at 14:33:56.617363: {'loss': 0.5298946601271629, 'accuracy': 0.818275, 'val_loss': 0.9709497807891505, 'val_accuracy': 0.6876}\n",
      "Epoch 5 ends at 14:36:01.809833: {'loss': 0.40691206282377246, 'accuracy': 0.85755, 'val_loss': 0.801623605618811, 'val_accuracy': 0.7405}\n",
      "Epoch 6 ends at 14:38:06.600600: {'loss': 0.31278612371683123, 'accuracy': 0.889675, 'val_loss': 0.7063474468175014, 'val_accuracy': 0.7869}\n",
      "Epoch 7 ends at 14:40:12.434451: {'loss': 0.24102993073165416, 'accuracy': 0.9157375, 'val_loss': 0.7287501990795135, 'val_accuracy': 0.8007}\n",
      "Epoch 8 ends at 14:42:18.981681: {'loss': 0.20603421991467477, 'accuracy': 0.9276375, 'val_loss': 1.0548455665825278, 'val_accuracy': 0.7391}\n",
      "Epoch 9 ends at 14:44:25.567590: {'loss': 0.16932210711464285, 'accuracy': 0.94115, 'val_loss': 0.8076304140364289, 'val_accuracy': 0.7922}\n",
      "Epoch 10 ends at 14:46:37.104535: {'loss': 0.14832350337579847, 'accuracy': 0.9488, 'val_loss': 0.9254404378544753, 'val_accuracy': 0.7828}\n",
      "Epoch 11 ends at 14:48:49.503936: {'loss': 0.12726307435370982, 'accuracy': 0.95585, 'val_loss': 0.8410139239517747, 'val_accuracy': 0.7982}\n",
      "Epoch 12 ends at 14:51:01.335856: {'loss': 0.1180645119279623, 'accuracy': 0.9595875, 'val_loss': 0.8657499999757026, 'val_accuracy': 0.803}\n",
      "Epoch 13 ends at 14:53:12.347265: {'loss': 0.10962354807667435, 'accuracy': 0.9619875, 'val_loss': 0.9896010202207383, 'val_accuracy': 0.7957}\n",
      "Epoch 14 ends at 14:55:25.281530: {'loss': 0.09735804678238928, 'accuracy': 0.966725, 'val_loss': 0.8799360941170128, 'val_accuracy': 0.8161}\n",
      "Epoch 15 ends at 15:07:43.177299: {'loss': 0.10000562313375995, 'accuracy': 0.966275, 'val_loss': 0.9557665848428276, 'val_accuracy': 0.7942}\n",
      "Epoch 16 ends at 15:09:51.173474: {'loss': 0.08909501664154232, 'accuracy': 0.9699625, 'val_loss': 0.9417236637157999, 'val_accuracy': 0.802}\n",
      "Epoch 17 ends at 15:12:02.494017: {'loss': 0.08580523035787047, 'accuracy': 0.9698375, 'val_loss': 1.1443160740053577, 'val_accuracy': 0.78}\n",
      "Epoch 18 ends at 15:14:14.048930: {'loss': 0.07712113511136268, 'accuracy': 0.9734875, 'val_loss': 1.0046570929372387, 'val_accuracy': 0.775}\n",
      "Epoch 19 ends at 15:16:26.550105: {'loss': 0.07308099573184736, 'accuracy': 0.9755125, 'val_loss': 0.902589995769938, 'val_accuracy': 0.8168}\n",
      "Epoch 20 ends at 15:18:39.495873: {'loss': 0.06587562594586052, 'accuracy': 0.977425, 'val_loss': 0.9775514796281316, 'val_accuracy': 0.8147}\n",
      "Epoch 21 ends at 15:20:52.909032: {'loss': 0.0657790161954239, 'accuracy': 0.978375, 'val_loss': 0.9499639360008726, 'val_accuracy': 0.8123}\n",
      "Epoch 22 ends at 15:23:06.971456: {'loss': 0.06329972382131964, 'accuracy': 0.9784875, 'val_loss': 1.002668892122378, 'val_accuracy': 0.8094}\n",
      "Epoch 23 ends at 15:25:20.190296: {'loss': 0.06116052499921061, 'accuracy': 0.97915, 'val_loss': 0.9821539536403243, 'val_accuracy': 0.8015}\n",
      "Epoch 24 ends at 15:27:33.331207: {'loss': 0.05587081894706935, 'accuracy': 0.980675, 'val_loss': 0.9884542710841842, 'val_accuracy': 0.8182}\n",
      "Epoch 25 ends at 15:29:46.075218: {'loss': 0.05284518313906156, 'accuracy': 0.9823875, 'val_loss': 1.1774328499083306, 'val_accuracy': 0.7896}\n",
      "Epoch 26 ends at 15:31:57.388509: {'loss': 0.056471503484528514, 'accuracy': 0.9810625, 'val_loss': 0.9696401281721273, 'val_accuracy': 0.8195}\n",
      "Epoch 27 ends at 15:34:10.260342: {'loss': 0.04936495910515078, 'accuracy': 0.9830375, 'val_loss': 1.1513730688079906, 'val_accuracy': 0.8007}\n",
      "Epoch 28 ends at 15:36:23.739457: {'loss': 0.04966064839774044, 'accuracy': 0.98335, 'val_loss': 1.1647451056796274, 'val_accuracy': 0.8057}\n",
      "Epoch 29 ends at 15:38:38.034386: {'loss': 0.05142090543922968, 'accuracy': 0.983075, 'val_loss': 0.9603910076010759, 'val_accuracy': 0.8121}\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,\n",
    "                    epochs=30,\n",
    "                    validation_data=valid_data,\n",
    "                    verbose=0,\n",
    "                    callbacks=[cp_callback, MyCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================].6005 - accuracy: 0.85 - 0s 68ms/step - loss: 0.8668 - accuracy: 0.82 - 0s 61ms/step - loss: 0.8802 - accuracy: 0.83 - 0s 59ms/step - loss: 0.8299 - accuracy: 0.82 - 0s 58ms/step - loss: 0.8273 - accuracy: 0.82 - 0s 56ms/step - loss: 0.7870 - accuracy: 0.82 - 0s 55ms/step - loss: 0.8308 - accuracy: 0.81 - 0s 54ms/step - loss: 0.8693 - accuracy: 0.80 - 0s 53ms/step - loss: 0.8250 - accuracy: 0.81 - 1s 53ms/step - loss: 0.8676 - accuracy: 0.81 - 1s 53ms/step - loss: 0.8423 - accuracy: 0.81 - 1s 52ms/step - loss: 0.8678 - accuracy: 0.81 - 1s 51ms/step - loss: 0.8725 - accuracy: 0.81 - 1s 51ms/step - loss: 0.8657 - accuracy: 0.81 - 1s 50ms/step - loss: 0.8682 - accuracy: 0.81 - 1s 50ms/step - loss: 0.9109 - accuracy: 0.80 - 1s 51ms/step - loss: 0.9057 - accuracy: 0.80 - 1s 52ms/step - loss: 0.9130 - accuracy: 0.80 - 1s 51ms/step - loss: 0.9137 - accuracy: 0.80 - 1s 51ms/step - loss: 0.9335 - accuracy: 0.80 - 1s 51ms/step - loss: 0.9190 - accuracy: 0.80 - 1s 52ms/step - loss: 0.9138 - accuracy: 0.81 - 1s 52ms/step - loss: 0.9065 - accuracy: 0.81 - 1s 52ms/step - loss: 0.9037 - accuracy: 0.81 - 1s 52ms/step - loss: 0.9074 - accuracy: 0.81 - 1s 52ms/step - loss: 0.9235 - accuracy: 0.81 - 1s 52ms/step - loss: 0.9192 - accuracy: 0.81 - 1s 52ms/step - loss: 0.9044 - accuracy: 0.81 - 1s 52ms/step - loss: 0.9087 - accuracy: 0.81 - 2s 51ms/step - loss: 0.9098 - accuracy: 0.81 - 2s 51ms/step - loss: 0.9106 - accuracy: 0.81 - 2s 51ms/step - loss: 0.9065 - accuracy: 0.81 - 2s 51ms/step - loss: 0.9252 - accuracy: 0.81 - 2s 51ms/step - loss: 0.9257 - accuracy: 0.81 - 2s 51ms/step - loss: 0.9267 - accuracy: 0.81 - 2s 50ms/step - loss: 0.9332 - accuracy: 0.81 - 2s 50ms/step - loss: 0.9390 - accuracy: 0.81 - 2s 50ms/step - loss: 0.9437 - accuracy: 0.81 - 2s 50ms/step - loss: 0.9401 - accuracy: 0.81 - 2s 50ms/step - loss: 0.9493 - accuracy: 0.81 - 2s 50ms/step - loss: 0.9606 - accuracy: 0.81 - 2s 50ms/step - loss: 0.9545 - accuracy: 0.81 - 2s 50ms/step - loss: 0.9635 - accuracy: 0.81 - 2s 50ms/step - loss: 0.9624 - accuracy: 0.81 - 2s 50ms/step - loss: 0.9548 - accuracy: 0.81 - 2s 50ms/step - loss: 0.9604 - accuracy: 0.81 - 2s 50ms/step - loss: 0.9630 - accuracy: 0.81 - 2s 50ms/step - loss: 0.9596 - accuracy: 0.81 - 2s 49ms/step - loss: 0.9600 - accuracy: 0.81 - 2s 49ms/step - loss: 0.9601 - accuracy: 0.81 - 3s 49ms/step - loss: 0.9589 - accuracy: 0.81 - 3s 49ms/step - loss: 0.9746 - accuracy: 0.81 - 3s 49ms/step - loss: 0.9843 - accuracy: 0.80 - 3s 49ms/step - loss: 0.9918 - accuracy: 0.80 - 3s 49ms/step - loss: 0.9946 - accuracy: 0.80 - 3s 49ms/step - loss: 0.9969 - accuracy: 0.80 - 3s 49ms/step - loss: 1.0000 - accuracy: 0.80 - 3s 49ms/step - loss: 0.9917 - accuracy: 0.80 - 3s 49ms/step - loss: 0.9864 - accuracy: 0.80 - 3s 49ms/step - loss: 0.9901 - accuracy: 0.80 - 3s 49ms/step - loss: 0.9893 - accuracy: 0.80 - 3s 49ms/step - loss: 0.9904 - accuracy: 0.80 - 3s 49ms/step - loss: 0.9875 - accuracy: 0.80 - 3s 50ms/step - loss: 0.9965 - accuracy: 0.80 - 3s 50ms/step - loss: 0.9974 - accuracy: 0.80 - 3s 50ms/step - loss: 0.9983 - accuracy: 0.80 - 3s 50ms/step - loss: 0.9991 - accuracy: 0.80 - 3s 50ms/step - loss: 1.0007 - accuracy: 0.80 - 3s 50ms/step - loss: 0.9954 - accuracy: 0.80 - 3s 50ms/step - loss: 0.9935 - accuracy: 0.80 - 4s 50ms/step - loss: 0.9969 - accuracy: 0.80 - 4s 49ms/step - loss: 1.0051 - accuracy: 0.80 - 4s 49ms/step - loss: 1.0187 - accuracy: 0.80 - 4s 49ms/step - loss: 1.0159 - accuracy: 0.80 - 4s 49ms/step - loss: 1.0178 - accuracy: 0.80 - 4s 49ms/step - loss: 1.0136 - accuracy: 0.80 - 4s 49ms/step - loss: 1.0122 - accuracy: 0.80 - 4s 49ms/step - loss: 1.0072 - accuracy: 0.80 - 4s 49ms/step - loss: 1.0019 - accuracy: 0.80 - 4s 49ms/step - loss: 0.9982 - accuracy: 0.80 - 4s 49ms/step - loss: 0.9979 - accuracy: 0.80 - 4s 49ms/step - loss: 0.9964 - accuracy: 0.80 - 4s 49ms/step - loss: 0.9990 - accuracy: 0.80 - 4s 49ms/step - loss: 0.9949 - accuracy: 0.80 - 4s 49ms/step - loss: 0.9939 - accuracy: 0.80 - 4s 49ms/step - loss: 0.9995 - accuracy: 0.80 - 4s 49ms/step - loss: 0.9981 - accuracy: 0.80 - 4s 49ms/step - loss: 0.9938 - accuracy: 0.80 - 4s 49ms/step - loss: 0.9924 - accuracy: 0.80 - 4s 49ms/step - loss: 0.9951 - accuracy: 0.80 - 4s 49ms/step - loss: 0.9930 - accuracy: 0.80 - 5s 49ms/step - loss: 0.9954 - accuracy: 0.80 - 5s 49ms/step - loss: 0.9941 - accuracy: 0.80 - 5s 49ms/step - loss: 1.0002 - accuracy: 0.80 - 5s 49ms/step - loss: 1.0043 - accuracy: 0.80 - 5s 49ms/step - loss: 1.0049 - accuracy: 0.80 - 5s 49ms/step - loss: 1.0081 - accuracy: 0.80 - 5s 49ms/step - loss: 1.0053 - accuracy: 0.80 - 5s 49ms/step - loss: 1.0036 - accuracy: 0.80 - 5s 49ms/step - loss: 1.0028 - accuracy: 0.80 - 5s 49ms/step - loss: 1.0063 - accuracy: 0.80 - 5s 49ms/step - loss: 1.0033 - accuracy: 0.80 - 5s 49ms/step - loss: 0.9995 - accuracy: 0.80 - 5s 49ms/step - loss: 1.0034 - accuracy: 0.80 - 5s 49ms/step - loss: 1.0073 - accuracy: 0.80 - 5s 49ms/step - loss: 1.0069 - accuracy: 0.80 - 5s 49ms/step - loss: 1.0043 - accuracy: 0.80 - 5s 49ms/step - loss: 1.0080 - accuracy: 0.80 - 5s 49ms/step - loss: 1.0101 - accuracy: 0.80 - 5s 49ms/step - loss: 1.0148 - accuracy: 0.80 - 5s 49ms/step - loss: 1.0105 - accuracy: 0.80 - 6s 49ms/step - loss: 1.0148 - accuracy: 0.80 - 6s 49ms/step - loss: 1.0169 - accuracy: 0.80 - 6s 49ms/step - loss: 1.0161 - accuracy: 0.80 - 6s 49ms/step - loss: 1.0170 - accuracy: 0.80 - 6s 49ms/step - loss: 1.0174 - accuracy: 0.80 - 6s 49ms/step - loss: 1.0187 - accuracy: 0.80 - 6s 49ms/step - loss: 1.0172 - accuracy: 0.80 - 6s 49ms/step - loss: 1.0145 - accuracy: 0.80 - 6s 49ms/step - loss: 1.0144 - accuracy: 0.80 - 6s 49ms/step - loss: 1.0143 - accuracy: 0.80 - 6s 49ms/step - loss: 1.0138 - accuracy: 0.80 - 6s 49ms/step - loss: 1.0134 - accuracy: 0.80 - 6s 49ms/step - loss: 1.0182 - accuracy: 0.80 - 6s 49ms/step - loss: 1.0164 - accuracy: 0.80 - 6s 49ms/step - loss: 1.0152 - accuracy: 0.80 - 6s 49ms/step - loss: 1.0157 - accuracy: 0.80 - 6s 49ms/step - loss: 1.0169 - accuracy: 0.80 - 6s 49ms/step - loss: 1.0185 - accuracy: 0.80 - 6s 49ms/step - loss: 1.0147 - accuracy: 0.80 - 6s 49ms/step - loss: 1.0141 - accuracy: 0.80 - 6s 49ms/step - loss: 1.0118 - accuracy: 0.80 - 7s 49ms/step - loss: 1.0116 - accuracy: 0.80 - 7s 49ms/step - loss: 1.0118 - accuracy: 0.80 - 7s 49ms/step - loss: 1.0084 - accuracy: 0.80 - 7s 49ms/step - loss: 1.0106 - accuracy: 0.80 - 7s 49ms/step - loss: 1.0125 - accuracy: 0.80 - 7s 49ms/step - loss: 1.0136 - accuracy: 0.80 - 7s 49ms/step - loss: 1.0145 - accuracy: 0.80 - 7s 49ms/step - loss: 1.0125 - accuracy: 0.80 - 7s 49ms/step - loss: 1.0168 - accuracy: 0.80 - 7s 49ms/step - loss: 1.0169 - accuracy: 0.80 - 7s 49ms/step - loss: 1.0165 - accuracy: 0.80 - 7s 49ms/step - loss: 1.0145 - accuracy: 0.80 - 7s 49ms/step - loss: 1.0112 - accuracy: 0.80 - 7s 49ms/step - loss: 1.0099 - accuracy: 0.80 - 7s 49ms/step - loss: 1.0080 - accuracy: 0.80 - 7s 49ms/step - loss: 1.0077 - accuracy: 0.80 - 7s 49ms/step - loss: 1.0080 - accuracy: 0.80 - 7s 49ms/step - loss: 1.0079 - accuracy: 0.80 - 7s 49ms/step - loss: 1.0051 - accuracy: 0.80 - 7s 49ms/step - loss: 1.0042 - accuracy: 0.80 - 8s 49ms/step - loss: 1.0026 - accuracy: 0.80 - 8s 49ms/step - loss: 1.0028 - accuracy: 0.80 - 8s 49ms/step - loss: 1.0014 - accuracy: 0.80 - 8s 49ms/step - loss: 1.0032 - accuracy: 0.80 - 8s 49ms/step - loss: 1.0006 - accuracy: 0.80 - 8s 51ms/step - loss: 1.0006 - accuracy: 0.8053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0005776661976127, 0.8053]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.models.load_model('checkpoints/{}.hdf5'.format(dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat 숫자를 4->2로 낮춤. epoch 속도 증가, epoch 처음 올라갈때 정확도 떨어짐. (l2 추가하니까, 속도가 조금 느려진 것 같기도 함.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
