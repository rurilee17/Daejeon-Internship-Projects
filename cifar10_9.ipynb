{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-datasets in c:\\users\\affinity\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: future in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.17.1)\n",
      "Requirement already satisfied: promise in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (2.2.1)\n",
      "Requirement already satisfied: termcolor in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (4.36.1)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.15.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (3.9.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (1.16.5)\n",
      "Requirement already satisfied: wrapt in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (1.11.2)\n",
      "Requirement already satisfied: dill in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.3.1.1)\n",
      "Requirement already satisfied: six in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (1.12.0)\n",
      "Requirement already satisfied: attrs in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (19.3.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (2.22.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.8.0)\n",
      "Requirement already satisfied: googleapis-common-protos in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow-metadata->tensorflow-datasets) (1.6.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow-datasets) (41.4.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in c:\\users\\affinity\\anaconda3\\lib\\site-packages (19.3.1)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.models import load_model\n",
    "from datetime import datetime\n",
    "#tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tfds.load(name='cifar10:3.*.*', split='train[:80%]', as_supervised=True)\n",
    "valid_data = tfds.load(name='cifar10:3.*.*', split='train[80%:]', as_supervised=True)\n",
    "test_data = tfds.load(name='cifar10:3.*.*', split='test', as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 128)       3584      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                81930     \n",
      "=================================================================\n",
      "Total params: 1,564,426\n",
      "Trainable params: 1,562,634\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.BatchNormalization(),  # Gradient Vanishing / Gradient Exploding 이 일어나지 않도록 하는 아이디어 중의 하나이다\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),  # Gradient Vanishing / Gradient Exploding 이 일어나지 않도록 하는 아이디어 중의 하나이다\n",
    "    tf.keras.layers.MaxPooling2D(),    \n",
    "    tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),  # Gradient Vanishing / Gradient Exploding 이 일어나지 않도록 하는 아이디어 중의 하나이다\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "    \n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    return image, label\n",
    "\n",
    "train_data = train_data.map(scale).shuffle(50000).batch(64) # \n",
    "valid_data = valid_data.map(scale).batch(64)\n",
    "test_data = test_data.map(scale).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(   \n",
    "    'checkpoints/{}.hdf5'.format(dt),\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def on_epoch_start(self, epoch, logs=None):\n",
    "        print('Epoch {} begins at {}: {}'.format(epoch, datetime.now().time(), logs))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print('Epoch {} ends at {}: {}'.format(epoch, datetime.now().time(), logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 ends at 17:23:25.783378: {'loss': 2.1964595123291017, 'accuracy': 0.465625, 'val_loss': 1.632261952017523, 'val_accuracy': 0.5005}\n",
      "Epoch 1 ends at 17:24:06.301068: {'loss': 1.4876708639144898, 'accuracy': 0.60985, 'val_loss': 1.5233012422634538, 'val_accuracy': 0.5798}\n",
      "Epoch 2 ends at 17:24:48.778383: {'loss': 1.214648219871521, 'accuracy': 0.664325, 'val_loss': 1.1766602465301563, 'val_accuracy': 0.6805}\n",
      "Epoch 3 ends at 17:25:31.400199: {'loss': 0.9705186642169953, 'accuracy': 0.7169, 'val_loss': 1.1392768484771632, 'val_accuracy': 0.6809}\n",
      "Epoch 4 ends at 17:26:13.572279: {'loss': 0.784703432559967, 'accuracy': 0.759875, 'val_loss': 1.1141847706144783, 'val_accuracy': 0.6688}\n",
      "Epoch 5 ends at 17:26:55.866015: {'loss': 0.6874556879281998, 'accuracy': 0.784625, 'val_loss': 2.6635124330308027, 'val_accuracy': 0.5465}\n",
      "Epoch 6 ends at 17:27:37.487494: {'loss': 0.552667821264267, 'accuracy': 0.818475, 'val_loss': 0.9551012107900753, 'val_accuracy': 0.7296}\n",
      "Epoch 7 ends at 17:28:19.456831: {'loss': 0.46149322847127916, 'accuracy': 0.843475, 'val_loss': 1.0365649317480197, 'val_accuracy': 0.7137}\n",
      "Epoch 8 ends at 17:29:01.279091: {'loss': 0.3835616411447525, 'accuracy': 0.86815, 'val_loss': 1.1041451240800748, 'val_accuracy': 0.7028}\n",
      "Epoch 9 ends at 17:29:43.821081: {'loss': 0.3363408601045609, 'accuracy': 0.884225, 'val_loss': 0.9540535602599952, 'val_accuracy': 0.7487}\n",
      "Epoch 10 ends at 17:30:25.834548: {'loss': 0.2860643985927105, 'accuracy': 0.90325, 'val_loss': 0.919066142694206, 'val_accuracy': 0.7542}\n",
      "Epoch 11 ends at 17:31:07.365573: {'loss': 0.25431525626182555, 'accuracy': 0.912975, 'val_loss': 0.8790936116959639, 'val_accuracy': 0.7713}\n",
      "Epoch 12 ends at 17:31:48.989429: {'loss': 0.2180745819032192, 'accuracy': 0.92405, 'val_loss': 1.1725715402584926, 'val_accuracy': 0.7201}\n",
      "Epoch 13 ends at 17:32:31.019419: {'loss': 0.1895570727288723, 'accuracy': 0.934325, 'val_loss': 1.1281435557991077, 'val_accuracy': 0.7575}\n",
      "Epoch 14 ends at 17:33:13.359991: {'loss': 0.17401513457894324, 'accuracy': 0.94085, 'val_loss': 1.0364312837078313, 'val_accuracy': 0.7665}\n",
      "Epoch 15 ends at 17:33:55.404134: {'loss': 0.16155255036354066, 'accuracy': 0.94525, 'val_loss': 0.9942539945529525, 'val_accuracy': 0.774}\n",
      "Epoch 16 ends at 17:34:36.972796: {'loss': 0.15098022458702326, 'accuracy': 0.949, 'val_loss': 1.0958582424813774, 'val_accuracy': 0.7686}\n",
      "Epoch 17 ends at 17:35:18.852277: {'loss': 0.15041607986837627, 'accuracy': 0.94975, 'val_loss': 1.2500534915620354, 'val_accuracy': 0.7214}\n",
      "Epoch 18 ends at 17:36:01.280298: {'loss': 0.13234749507009982, 'accuracy': 0.95435, 'val_loss': 1.297634754970575, 'val_accuracy': 0.739}\n",
      "Epoch 19 ends at 17:36:43.317256: {'loss': 0.12371450368836522, 'accuracy': 0.95785, 'val_loss': 1.1362212326875918, 'val_accuracy': 0.7678}\n",
      "Epoch 20 ends at 17:37:25.079009: {'loss': 0.1192861089553684, 'accuracy': 0.958775, 'val_loss': 1.2017936019381141, 'val_accuracy': 0.7555}\n",
      "Epoch 21 ends at 17:38:07.305622: {'loss': 0.10919390534833073, 'accuracy': 0.963, 'val_loss': 1.1584621683047835, 'val_accuracy': 0.7767}\n",
      "Epoch 22 ends at 17:38:49.227490: {'loss': 0.10516374726183712, 'accuracy': 0.9638, 'val_loss': 1.2508161903186967, 'val_accuracy': 0.762}\n",
      "Epoch 23 ends at 17:39:31.240729: {'loss': 0.10964164020344615, 'accuracy': 0.961825, 'val_loss': 1.1473586160665865, 'val_accuracy': 0.7752}\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,\n",
    "                    epochs=24,\n",
    "                    validation_data=valid_data,\n",
    "                    verbose=0,\n",
    "                    callbacks=[cp_callback, MyCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================].2636 - accuracy: 0.75 - 0s 58ms/step - loss: 1.2982 - accuracy: 0.75 - 0s 48ms/step - loss: 1.5514 - accuracy: 0.75 - 0s 43ms/step - loss: 1.4133 - accuracy: 0.75 - 0s 40ms/step - loss: 1.2891 - accuracy: 0.76 - 0s 38ms/step - loss: 1.2123 - accuracy: 0.78 - 0s 37ms/step - loss: 1.2636 - accuracy: 0.78 - 0s 35ms/step - loss: 1.3100 - accuracy: 0.76 - 0s 34ms/step - loss: 1.2713 - accuracy: 0.76 - 0s 34ms/step - loss: 1.3037 - accuracy: 0.75 - 0s 33ms/step - loss: 1.2212 - accuracy: 0.77 - 0s 33ms/step - loss: 1.2520 - accuracy: 0.76 - 0s 33ms/step - loss: 1.2464 - accuracy: 0.76 - 0s 33ms/step - loss: 1.2372 - accuracy: 0.76 - 0s 32ms/step - loss: 1.2661 - accuracy: 0.75 - 1s 32ms/step - loss: 1.3295 - accuracy: 0.75 - 1s 31ms/step - loss: 1.3394 - accuracy: 0.74 - 1s 31ms/step - loss: 1.3439 - accuracy: 0.74 - 1s 31ms/step - loss: 1.3175 - accuracy: 0.75 - 1s 31ms/step - loss: 1.2996 - accuracy: 0.75 - 1s 31ms/step - loss: 1.2620 - accuracy: 0.75 - 1s 31ms/step - loss: 1.2449 - accuracy: 0.76 - 1s 31ms/step - loss: 1.2390 - accuracy: 0.76 - 1s 30ms/step - loss: 1.2294 - accuracy: 0.76 - 1s 31ms/step - loss: 1.2296 - accuracy: 0.76 - 1s 31ms/step - loss: 1.2306 - accuracy: 0.76 - 1s 31ms/step - loss: 1.2251 - accuracy: 0.76 - 1s 30ms/step - loss: 1.2200 - accuracy: 0.76 - 1s 30ms/step - loss: 1.2019 - accuracy: 0.76 - 1s 30ms/step - loss: 1.2040 - accuracy: 0.76 - 1s 30ms/step - loss: 1.1993 - accuracy: 0.76 - 1s 29ms/step - loss: 1.1832 - accuracy: 0.77 - 1s 29ms/step - loss: 1.2058 - accuracy: 0.76 - 1s 29ms/step - loss: 1.2029 - accuracy: 0.76 - 1s 29ms/step - loss: 1.2002 - accuracy: 0.76 - 1s 29ms/step - loss: 1.2031 - accuracy: 0.76 - 1s 29ms/step - loss: 1.2126 - accuracy: 0.76 - 1s 29ms/step - loss: 1.2055 - accuracy: 0.77 - 1s 29ms/step - loss: 1.2090 - accuracy: 0.77 - 1s 29ms/step - loss: 1.2162 - accuracy: 0.77 - 1s 29ms/step - loss: 1.2229 - accuracy: 0.76 - 1s 29ms/step - loss: 1.2119 - accuracy: 0.77 - 1s 29ms/step - loss: 1.2161 - accuracy: 0.77 - 1s 29ms/step - loss: 1.2259 - accuracy: 0.76 - 1s 29ms/step - loss: 1.2254 - accuracy: 0.76 - 1s 29ms/step - loss: 1.2185 - accuracy: 0.76 - 1s 29ms/step - loss: 1.2137 - accuracy: 0.76 - 1s 29ms/step - loss: 1.2081 - accuracy: 0.77 - 1s 28ms/step - loss: 1.2314 - accuracy: 0.76 - 1s 28ms/step - loss: 1.2279 - accuracy: 0.76 - 1s 28ms/step - loss: 1.2271 - accuracy: 0.76 - 1s 28ms/step - loss: 1.2394 - accuracy: 0.76 - 1s 28ms/step - loss: 1.2465 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2480 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2401 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2414 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2437 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2426 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2461 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2535 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2497 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2510 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2459 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2453 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2476 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2451 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2516 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2570 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2548 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2573 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2578 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2612 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2742 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2674 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2699 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2618 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2606 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2587 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2588 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2560 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2550 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2499 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2459 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2484 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2488 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2485 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2485 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2466 - accuracy: 0.76 - 2s 28ms/step - loss: 1.2458 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2452 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2470 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2481 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2442 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2515 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2533 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2509 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2559 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2524 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2598 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2611 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2642 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2601 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2583 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2650 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2579 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2632 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2630 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2605 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2621 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2645 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2604 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2628 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2667 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2623 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2627 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2622 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2578 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2574 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2576 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2565 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2556 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2545 - accuracy: 0.76 - 3s 28ms/step - loss: 1.2532 - accuracy: 0.76 - 3s 27ms/step - loss: 1.2561 - accuracy: 0.76 - 3s 27ms/step - loss: 1.2527 - accuracy: 0.76 - 3s 27ms/step - loss: 1.2493 - accuracy: 0.76 - 3s 27ms/step - loss: 1.2526 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2537 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2544 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2531 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2510 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2520 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2502 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2490 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2469 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2506 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2520 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2528 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2561 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2530 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2567 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2544 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2559 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2577 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2561 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2556 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2556 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2554 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2527 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2520 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2492 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2450 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2441 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2420 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2387 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2377 - accuracy: 0.76 - 4s 27ms/step - loss: 1.2368 - accuracy: 0.76 - 4s 28ms/step - loss: 1.2368 - accuracy: 0.7676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2367899247035858, 0.7676]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.models.load_model('checkpoints/{}.hdf5'.format(dt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
